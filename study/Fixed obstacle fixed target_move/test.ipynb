{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:29:38.881233900Z",
     "start_time": "2024-04-18T07:29:38.856234200Z"
    }
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import env_test1\n",
    "env = env_test1.DroneEnv()\n",
    "check_env(env)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84c32894c611bf66"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./tensorboard/ppo_run_1713425380.3104565_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1141 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-5494.55 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 501           |\n",
      "|    mean_reward          | -5.49e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 4000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050675636 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | -9.3e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.82e+05      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000972     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 1.05e+06      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 589  |\n",
      "|    iterations      | 2    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004993662 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -0.000726    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+05     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000803    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.78e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-7125.34 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 501          |\n",
      "|    mean_reward          | -7.13e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.799175e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.000134     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.75e+06     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000384    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.79e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 542  |\n",
      "|    iterations      | 4    |\n",
      "|    time_elapsed    | 15   |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 570           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044678478 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | -0.000124     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.65e+05      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000635     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 6.66e+05      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-5508.85 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 501          |\n",
      "|    mean_reward          | -5.51e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002697408 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -3.7e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+05     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000269    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.6e+05      |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 533   |\n",
      "|    iterations      | 6     |\n",
      "|    time_elapsed    | 23    |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 552           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037724746 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | -3.05e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.04e+05      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.000714     |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 8.11e+05      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-5372.66 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 501           |\n",
      "|    mean_reward          | -5.37e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2871787e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 7.93e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.05e+06      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.000151     |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 5.84e+06      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 529   |\n",
      "|    iterations      | 8     |\n",
      "|    time_elapsed    | 30    |\n",
      "|    total_timesteps | 16384 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 543           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0225947e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 7.21e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.71e+06      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000367     |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 8.61e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-5263.75 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 501          |\n",
      "|    mean_reward          | -5.26e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.789095e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 5.96e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.38e+06     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000472    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 6.01e+06     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 526   |\n",
      "|    iterations      | 10    |\n",
      "|    time_elapsed    | 38    |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002263787 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 9.3e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.45e+05     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000956    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 2.72e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-5453.24 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 501           |\n",
      "|    mean_reward          | -5.45e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 24000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2162265e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 4.23e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.84e+06      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000384     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 1.33e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 525   |\n",
      "|    iterations      | 12    |\n",
      "|    time_elapsed    | 46    |\n",
      "|    total_timesteps | 24576 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 535          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.742202e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 5.36e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+06     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000564    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 4.34e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-5354.16 +/- 0.00\n",
      "Episode length: 501.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 501           |\n",
      "|    mean_reward          | -5.35e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 28000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050608447 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.47         |\n",
      "|    explained_variance   | 3.1e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.05e+06      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 2.9e+06       |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 523   |\n",
      "|    iterations      | 14    |\n",
      "|    time_elapsed    | 54    |\n",
      "|    total_timesteps | 28672 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005399811 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -1.35e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.81e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.03e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-4232.29 +/- 0.00\n",
      "Episode length: 456.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 456         |\n",
      "|    mean_reward          | -4.23e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002075362 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 8.17e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71e+04    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.85e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 524   |\n",
      "|    iterations      | 16    |\n",
      "|    time_elapsed    | 62    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 532           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 65            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010413505 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 1.91e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7e+05         |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000675     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 1.11e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-4306.09 +/- 0.00\n",
      "Episode length: 461.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 461          |\n",
      "|    mean_reward          | -4.31e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 36000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.009612e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 1.25e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.92e+05     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000228    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.7e+06      |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 524   |\n",
      "|    iterations      | 18    |\n",
      "|    time_elapsed    | 70    |\n",
      "|    total_timesteps | 36864 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.193926e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 1.37e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+06     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000352    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.2e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-4383.91 +/- 0.00\n",
      "Episode length: 466.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 466          |\n",
      "|    mean_reward          | -4.38e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.352469e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 7.75e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.53e+06     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000282    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 7.79e+06     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 525   |\n",
      "|    iterations      | 20    |\n",
      "|    time_elapsed    | 78    |\n",
      "|    total_timesteps | 40960 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.222563e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 1.43e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+06      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000326    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 2.91e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=-4729.11 +/- 0.00\n",
      "Episode length: 489.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 489           |\n",
      "|    mean_reward          | -4.73e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 44000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012693935 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 9.54e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.05e+06      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.000482     |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 5.29e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 524   |\n",
      "|    iterations      | 22    |\n",
      "|    time_elapsed    | 85    |\n",
      "|    total_timesteps | 45056 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 528           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 89            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5172427e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 6.56e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.41e+06      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000246     |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 5.59e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-4215.46 +/- 0.00\n",
      "Episode length: 455.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 455           |\n",
      "|    mean_reward          | -4.22e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 48000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038242663 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | 1.13e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.6e+05       |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.000683     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 7.75e+05      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 522   |\n",
      "|    iterations      | 24    |\n",
      "|    time_elapsed    | 94    |\n",
      "|    total_timesteps | 49152 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 526           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 97            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6980328e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | 4.77e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.05e+06      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.000282     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 4.57e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-8945.42 +/- 0.00\n",
      "Episode length: 446.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 446           |\n",
      "|    mean_reward          | -8.95e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 52000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026610572 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | 7.15e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.22e+06      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000647     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 1.93e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 521   |\n",
      "|    iterations      | 26    |\n",
      "|    time_elapsed    | 102   |\n",
      "|    total_timesteps | 53248 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007255514 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 8.34e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.27e+05     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000852    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 7.97e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=-11129.86 +/- 0.00\n",
      "Episode length: 449.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 449          |\n",
      "|    mean_reward          | -1.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 56000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.905841e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 3.58e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+06     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000273    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 2.8e+06      |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 28    |\n",
      "|    time_elapsed    | 110   |\n",
      "|    total_timesteps | 57344 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 524           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 113           |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018728539 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 4.77e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.34e+05      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.000385     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 2.17e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-12983.51 +/- 0.00\n",
      "Episode length: 446.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 446          |\n",
      "|    mean_reward          | -1.3e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.299775e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 3.58e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.44e+06     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000561    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 4.73e+06     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 30    |\n",
      "|    time_elapsed    | 118   |\n",
      "|    total_timesteps | 61440 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011545316 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 4.77e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.32e+04    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.76e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-37934.70 +/- 0.00\n",
      "Episode length: 423.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 423          |\n",
      "|    mean_reward          | -3.79e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.472045e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.35e+06     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000269    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 7.29e+06     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 32    |\n",
      "|    time_elapsed    | 125   |\n",
      "|    total_timesteps | 65536 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006431883 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.67e+06     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.67e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=-4079.67 +/- 0.00\n",
      "Episode length: 446.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 446           |\n",
      "|    mean_reward          | -4.08e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 68000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040138722 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.11e+06      |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.000924     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 3.55e+06      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 34    |\n",
      "|    time_elapsed    | 133   |\n",
      "|    total_timesteps | 69632 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 523           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045245176 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.09e+06      |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 3.28e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-4308.28 +/- 0.00\n",
      "Episode length: 461.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 461           |\n",
      "|    mean_reward          | -4.31e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 72000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012681106 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.27e+06      |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.000581     |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 5.16e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 519   |\n",
      "|    iterations      | 36    |\n",
      "|    time_elapsed    | 141   |\n",
      "|    total_timesteps | 73728 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 523          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011869632 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.25e+05     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 1.06e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=-4113.02 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 448          |\n",
      "|    mean_reward          | -4.11e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 76000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038010394 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 1.43e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.9e+04      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.96e+04     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 38    |\n",
      "|    time_elapsed    | 149   |\n",
      "|    total_timesteps | 77824 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 523          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079675205 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 8.34e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.8e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-25181.82 +/- 0.00\n",
      "Episode length: 428.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 428           |\n",
      "|    mean_reward          | -2.52e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 80000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050034793 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.6e+06       |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 2.97e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 40    |\n",
      "|    time_elapsed    | 157   |\n",
      "|    total_timesteps | 81920 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 523           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 160           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036730245 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.6e+05       |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.000919     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 3.75e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=-5701.80 +/- 0.00\n",
      "Episode length: 443.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 443           |\n",
      "|    mean_reward          | -5.7e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 84000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019857896 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.63e+06      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000864     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 4.37e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 520   |\n",
      "|    iterations      | 42    |\n",
      "|    time_elapsed    | 165   |\n",
      "|    total_timesteps | 86016 |\n",
      "------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=-11583.04 +/- 0.00\n",
      "Episode length: 442.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 442           |\n",
      "|    mean_reward          | -1.16e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 88000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016842701 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.79e+05      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000585     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 2.69e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 518   |\n",
      "|    iterations      | 43    |\n",
      "|    time_elapsed    | 169   |\n",
      "|    total_timesteps | 88064 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 520           |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 173           |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023355437 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.11e+05      |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.000507     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 6.99e+05      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=-4262.22 +/- 0.00\n",
      "Episode length: 458.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 458          |\n",
      "|    mean_reward          | -4.26e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 92000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006694003 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.35e+04     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00099     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.55e+05     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 517   |\n",
      "|    iterations      | 45    |\n",
      "|    time_elapsed    | 177   |\n",
      "|    total_timesteps | 92160 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 520           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 180           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030338153 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.47e+06      |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.000744     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 4.15e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-4082.13 +/- 0.00\n",
      "Episode length: 446.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 446          |\n",
      "|    mean_reward          | -4.08e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055319206 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 7.15e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+04     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 2.57e+04     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 518   |\n",
      "|    iterations      | 47    |\n",
      "|    time_elapsed    | 185   |\n",
      "|    total_timesteps | 96256 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007538483 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.78e+05     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 2.48e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-4560.66 +/- 0.00\n",
      "Episode length: 478.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 478         |\n",
      "|    mean_reward          | -4.56e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001443238 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.32e+05    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 2.39e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 518    |\n",
      "|    iterations      | 49     |\n",
      "|    time_elapsed    | 193    |\n",
      "|    total_timesteps | 100352 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035109394 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+05     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=-4291.30 +/- 0.00\n",
      "Episode length: 460.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 460         |\n",
      "|    mean_reward          | -4.29e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 104000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007472649 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14e+04    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 2.52e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 518    |\n",
      "|    iterations      | 51     |\n",
      "|    time_elapsed    | 201    |\n",
      "|    total_timesteps | 104448 |\n",
      "-------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 520           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 204           |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031366764 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.66e+04      |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.000288     |\n",
      "|    std                  | 0.969         |\n",
      "|    value_loss           | 1.09e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=-4321.97 +/- 0.00\n",
      "Episode length: 462.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 462          |\n",
      "|    mean_reward          | -4.32e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 108000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018040963 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.3e+04      |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 9.95e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 518    |\n",
      "|    iterations      | 53     |\n",
      "|    time_elapsed    | 209    |\n",
      "|    total_timesteps | 108544 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079919705 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+04     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    std                  | 0.898        |\n",
      "|    value_loss           | 2.44e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-16393.28 +/- 0.00\n",
      "Episode length: 435.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 435          |\n",
      "|    mean_reward          | -1.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 112000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062686848 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.56e+04     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    std                  | 0.881        |\n",
      "|    value_loss           | 6.04e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 519    |\n",
      "|    iterations      | 55     |\n",
      "|    time_elapsed    | 217    |\n",
      "|    total_timesteps | 112640 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015418946 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+06     |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.884        |\n",
      "|    value_loss           | 2.37e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=-4048.64 +/- 0.00\n",
      "Episode length: 444.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 444          |\n",
      "|    mean_reward          | -4.05e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 116000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.989468e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.5e+06      |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000315    |\n",
      "|    std                  | 0.888        |\n",
      "|    value_loss           | 2.3e+06      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 519    |\n",
      "|    iterations      | 57     |\n",
      "|    time_elapsed    | 224    |\n",
      "|    total_timesteps | 116736 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056837983 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.74e+03     |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 1.72e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-31983.88 +/- 0.00\n",
      "Episode length: 428.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 428          |\n",
      "|    mean_reward          | -3.2e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024697008 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.4e+04      |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    std                  | 0.893        |\n",
      "|    value_loss           | 1.41e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 59     |\n",
      "|    time_elapsed    | 232    |\n",
      "|    total_timesteps | 120832 |\n",
      "-------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 522           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 235           |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017959991 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.31         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.12e+05      |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.000914     |\n",
      "|    std                  | 0.895         |\n",
      "|    value_loss           | 1.28e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=-37981.47 +/- 0.00\n",
      "Episode length: 426.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 426          |\n",
      "|    mean_reward          | -3.8e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 124000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.641091e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.14e+06     |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000191    |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 3.18e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 61     |\n",
      "|    time_elapsed    | 239    |\n",
      "|    total_timesteps | 124928 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 523          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021907915 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+06     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 3.76e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=-17128.13 +/- 0.00\n",
      "Episode length: 432.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 432           |\n",
      "|    mean_reward          | -1.71e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 128000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024553176 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.3          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.84e+05      |\n",
      "|    n_updates            | 620           |\n",
      "|    policy_gradient_loss | -0.000552     |\n",
      "|    std                  | 0.884         |\n",
      "|    value_loss           | 1.98e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 521    |\n",
      "|    iterations      | 63     |\n",
      "|    time_elapsed    | 247    |\n",
      "|    total_timesteps | 129024 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 523        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 250        |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00168715 |\n",
      "|    clip_fraction        | 0.000635   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.69e+06   |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.00198   |\n",
      "|    std                  | 0.884      |\n",
      "|    value_loss           | 4.63e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=-21839.73 +/- 0.00\n",
      "Episode length: 432.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 432          |\n",
      "|    mean_reward          | -2.18e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 132000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006626649 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+06     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.000821    |\n",
      "|    std                  | 0.876        |\n",
      "|    value_loss           | 2.46e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 522    |\n",
      "|    iterations      | 65     |\n",
      "|    time_elapsed    | 255    |\n",
      "|    total_timesteps | 133120 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003635005 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+05    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.876       |\n",
      "|    value_loss           | 1.02e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=-15589.22 +/- 0.00\n",
      "Episode length: 434.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 434          |\n",
      "|    mean_reward          | -1.56e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 136000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017995641 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+05     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.865        |\n",
      "|    value_loss           | 1.88e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 522    |\n",
      "|    iterations      | 67     |\n",
      "|    time_elapsed    | 262    |\n",
      "|    total_timesteps | 137216 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025626104 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.69e+05     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    std                  | 0.873        |\n",
      "|    value_loss           | 1.18e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-4079.48 +/- 0.00\n",
      "Episode length: 446.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 446          |\n",
      "|    mean_reward          | -4.08e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056065163 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.04e+04     |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    std                  | 0.881        |\n",
      "|    value_loss           | 1.94e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 522    |\n",
      "|    iterations      | 69     |\n",
      "|    time_elapsed    | 270    |\n",
      "|    total_timesteps | 141312 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061549023 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.35e+05     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.884        |\n",
      "|    value_loss           | 1.38e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=-4155.59 +/- 0.00\n",
      "Episode length: 451.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 451          |\n",
      "|    mean_reward          | -4.16e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033600098 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.24e+03     |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    std                  | 0.872        |\n",
      "|    value_loss           | 1.49e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 523    |\n",
      "|    iterations      | 71     |\n",
      "|    time_elapsed    | 277    |\n",
      "|    total_timesteps | 145408 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040316535 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.97e+03     |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    std                  | 0.862        |\n",
      "|    value_loss           | 1.34e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=-4038.56 +/- 0.00\n",
      "Episode length: 443.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 443         |\n",
      "|    mean_reward          | -4.04e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 148000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002465618 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.75e+03    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 523    |\n",
      "|    iterations      | 73     |\n",
      "|    time_elapsed    | 285    |\n",
      "|    total_timesteps | 149504 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058341743 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 6.12e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=-3930.03 +/- 0.00\n",
      "Episode length: 436.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 436          |\n",
      "|    mean_reward          | -3.93e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 152000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010558878 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+06      |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 1.15e+06     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 522    |\n",
      "|    iterations      | 75     |\n",
      "|    time_elapsed    | 293    |\n",
      "|    total_timesteps | 153600 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037524654 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+06     |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    std                  | 0.846        |\n",
      "|    value_loss           | 7.26e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=156000, episode_reward=-4156.71 +/- 0.00\n",
      "Episode length: 451.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 451          |\n",
      "|    mean_reward          | -4.16e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 156000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033651714 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.25e+04     |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    std                  | 0.847        |\n",
      "|    value_loss           | 2.5e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 522    |\n",
      "|    iterations      | 77     |\n",
      "|    time_elapsed    | 302    |\n",
      "|    total_timesteps | 157696 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006367711 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.03e+04    |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 2.37e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-4006.09 +/- 0.00\n",
      "Episode length: 441.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 441          |\n",
      "|    mean_reward          | -4.01e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038947866 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.66e+03     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.809        |\n",
      "|    value_loss           | 1.18e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 79     |\n",
      "|    time_elapsed    | 310    |\n",
      "|    total_timesteps | 161792 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 522        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00594969 |\n",
      "|    clip_fraction        | 0.0485     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.59e+03   |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.00408   |\n",
      "|    std                  | 0.788      |\n",
      "|    value_loss           | 1.11e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=-3992.69 +/- 0.00\n",
      "Episode length: 440.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 440          |\n",
      "|    mean_reward          | -3.99e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 164000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016565936 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.29e+04     |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    std                  | 0.798        |\n",
      "|    value_loss           | 2.18e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 81     |\n",
      "|    time_elapsed    | 318    |\n",
      "|    total_timesteps | 165888 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 522        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 321        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00458479 |\n",
      "|    clip_fraction        | 0.0337     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.09e+05   |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.00281   |\n",
      "|    std                  | 0.803      |\n",
      "|    value_loss           | 4.29e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=-4153.87 +/- 0.00\n",
      "Episode length: 451.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 451          |\n",
      "|    mean_reward          | -4.15e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 168000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017916997 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+05      |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    std                  | 0.8          |\n",
      "|    value_loss           | 2.63e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 521    |\n",
      "|    iterations      | 83     |\n",
      "|    time_elapsed    | 326    |\n",
      "|    total_timesteps | 169984 |\n",
      "-------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=-4033.96 +/- 0.00\n",
      "Episode length: 443.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 443         |\n",
      "|    mean_reward          | -4.03e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 172000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005160619 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+04     |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 1.04e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 519    |\n",
      "|    iterations      | 84     |\n",
      "|    time_elapsed    | 331    |\n",
      "|    total_timesteps | 172032 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023138418 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.83e+05     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.798        |\n",
      "|    value_loss           | 1.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=-4021.08 +/- 0.00\n",
      "Episode length: 442.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 442         |\n",
      "|    mean_reward          | -4.02e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 176000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005310903 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.41e+03    |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.791       |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 519    |\n",
      "|    iterations      | 86     |\n",
      "|    time_elapsed    | 338    |\n",
      "|    total_timesteps | 176128 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005937433 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.45e+05    |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.8         |\n",
      "|    value_loss           | 3.09e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-4127.39 +/- 0.00\n",
      "Episode length: 449.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 449          |\n",
      "|    mean_reward          | -4.13e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 180000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026454523 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.27e+03     |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.000754    |\n",
      "|    std                  | 0.791        |\n",
      "|    value_loss           | 1.06e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 519    |\n",
      "|    iterations      | 88     |\n",
      "|    time_elapsed    | 346    |\n",
      "|    total_timesteps | 180224 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 349          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032224767 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.91e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    std                  | 0.777        |\n",
      "|    value_loss           | 9.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=-4202.97 +/- 0.00\n",
      "Episode length: 454.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 454          |\n",
      "|    mean_reward          | -4.2e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 184000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034227916 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.31e+04     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 1.78e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 519    |\n",
      "|    iterations      | 90     |\n",
      "|    time_elapsed    | 354    |\n",
      "|    total_timesteps | 184320 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 357          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023158514 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.54e+03     |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.000125    |\n",
      "|    std                  | 0.761        |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=-4112.77 +/- 0.00\n",
      "Episode length: 448.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 448          |\n",
      "|    mean_reward          | -4.11e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 188000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065966267 |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    std                  | 0.756        |\n",
      "|    value_loss           | 1.04e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 92     |\n",
      "|    time_elapsed    | 362    |\n",
      "|    total_timesteps | 188416 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026380662 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.83e+03     |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 8.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=-4095.55 +/- 0.00\n",
      "Episode length: 447.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 447          |\n",
      "|    mean_reward          | -4.1e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057250913 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.81e+03     |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 0.746        |\n",
      "|    value_loss           | 9.99e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 94     |\n",
      "|    time_elapsed    | 370    |\n",
      "|    total_timesteps | 192512 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 372          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034570908 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.33e+05     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.755        |\n",
      "|    value_loss           | 2.61e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=-4141.33 +/- 0.00\n",
      "Episode length: 450.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 450          |\n",
      "|    mean_reward          | -4.14e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 196000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018210695 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.03e+03     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000597    |\n",
      "|    std                  | 0.766        |\n",
      "|    value_loss           | 9.73e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 96     |\n",
      "|    time_elapsed    | 377    |\n",
      "|    total_timesteps | 196608 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 380          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026151335 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+05     |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    std                  | 0.76         |\n",
      "|    value_loss           | 1.32e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-4174.20 +/- 0.00\n",
      "Episode length: 452.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 452         |\n",
      "|    mean_reward          | -4.17e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004889439 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+04    |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 2.76e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 520    |\n",
      "|    iterations      | 98     |\n",
      "|    time_elapsed    | 385    |\n",
      "|    total_timesteps | 200704 |\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.ppo.ppo.PPO at 0x22356afceb0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#vec_env = VecNormalize(env, norm_obs=True, norm_reward=True,clip_obs=1)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./tensorboard/\",device=\"cuda\")\n",
    "# Evaluation callback\n",
    "callbacks = []\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    callback_on_new_best=None,\n",
    "    n_eval_episodes=8,\n",
    "    best_model_save_path=\".\",\n",
    "    log_path=\".\",\n",
    "    eval_freq=4000,\n",
    ")\n",
    "\n",
    "callbacks.append(eval_callback)\n",
    "kwargs = {}\n",
    "kwargs[\"callback\"] = callbacks\n",
    "\n",
    "log_name = \"ppo_run_\" + str(time.time())\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=200000,\n",
    "    tb_log_name=log_name,\n",
    "    **kwargs\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:36:07.025666400Z",
     "start_time": "2024-04-18T07:29:40.305265800Z"
    }
   },
   "id": "a6364eb784437bc7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: mean_reward:-3930.03 +/- 0.00\n",
      "After training: mean_reward:-3930.03 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Before training: mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "# 开始训练\n",
    "#model.learn(total_timesteps=100000,tb_log_name=log_name,\n",
    "    #**kwargs)\n",
    "# 评估训练后的 policy\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"After training: mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:37:32.369880600Z",
     "start_time": "2024-04-18T07:37:27.715387400Z"
    }
   },
   "id": "33bab43037b8499f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 绘图检验"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64de305199a42f8d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -3930.0314151019556\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个包含一个子图的窗口\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "env = env_test1.DroneEnv()\n",
    "\n",
    "# 重置环境\n",
    "state, info = env.reset()\n",
    "trajectory_x = [env.xy_p[0]]  # 存储无人机路径的x坐标\n",
    "trajectory_y = [env.xy_p[1]]  # 存储无人机路径的y坐标\n",
    "trajectory_ex = [env.xy_e[0]]  # 存储无人机路径的x坐标\n",
    "trajectory_ey = [env.xy_e[1]]  # 存储无人机路径的y坐标\n",
    "\n",
    "# 在子图中绘制环境和障碍物\n",
    "ax.scatter(env.xy_e[0], env.xy_e[1], marker='x', color='green', label='Goal')\n",
    "for k in env.obstacles:\n",
    "    obstacle_circle = plt.Circle(k, env.r_obstacles, color='lightblue', fill=True)\n",
    "    ax.add_patch(obstacle_circle)\n",
    "ax.set_xlim(env.space1.low[0], env.space1.high[0])\n",
    "ax.set_ylim(env.space1.low[1], env.space1.high[1])\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.set_title('Drone Path')\n",
    "\n",
    "# 通过预训练模型控制无人机执行任务并绘制路径\n",
    "#model = PPO.load(\"best_model\") \n",
    "done = False\n",
    "total_reward = 0\n",
    "count = 0\n",
    "while not done:\n",
    "    count += 1\n",
    "    action, _states = model.predict(state, deterministic=True)\n",
    "    next_state, reward, done, t, info = env.step(action)\n",
    "    #if reward < -10:\n",
    "        #print(state, action, reward)\n",
    "    if count > 500:\n",
    "        done = True\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    trajectory_x.append(env.xy_p[0])  # 更新无人机路径的x坐标\n",
    "    trajectory_y.append(env.xy_p[1])  # 更新无人机路径的y坐标\n",
    "    trajectory_ex.append(env.xy_e[0])  # 更新无人机路径的x坐标\n",
    "    trajectory_ey.append(env.xy_e[1])  # 更新无人机路径的y坐标\n",
    "\n",
    "# 绘制无人机路径\n",
    "ax.plot(trajectory_x, trajectory_y, color='red', linewidth=0.5)\n",
    "ax.plot(trajectory_ex, trajectory_ey, color='red', linewidth=0.5)\n",
    "\n",
    "# 打印每个episode的总奖励\n",
    "print('Total reward:', total_reward)\n",
    "\n",
    "# 显示子图窗口\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:37:33.752241500Z",
     "start_time": "2024-04-18T07:37:33.422526800Z"
    }
   },
   "id": "85b9e88968d1a4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -3930.0314151019556\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个包含一个子图的窗口\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "env = env_test1.DroneEnv()\n",
    "\n",
    "# 重置环境\n",
    "state, info = env.reset()\n",
    "trajectory_x = [env.xy_p[0]]  # 存储无人机路径的x坐标\n",
    "trajectory_y = [env.xy_p[1]]  # 存储无人机路径的y坐标\n",
    "trajectory_ex = [env.xy_e[0]]  # 存储无人机路径的x坐标\n",
    "trajectory_ey = [env.xy_e[1]]  # 存储无人机路径的y坐标\n",
    "\n",
    "# 在子图中绘制环境和障碍物\n",
    "ax.scatter(env.xy_e[0], env.xy_e[1], marker='x', color='green', label='Goal')\n",
    "for k in env.obstacles:\n",
    "    obstacle_circle = plt.Circle(k, env.r_obstacles, color='lightblue', fill=True)\n",
    "    ax.add_patch(obstacle_circle)\n",
    "ax.set_xlim(env.space1.low[0], env.space1.high[0])\n",
    "ax.set_ylim(env.space1.low[1], env.space1.high[1])\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.set_title('Drone Path')\n",
    "\n",
    "# 通过预训练模型控制无人机执行任务并绘制路径\n",
    "model = PPO.load(\"best_model\") \n",
    "done = False\n",
    "total_reward = 0\n",
    "count = 0\n",
    "while not done:\n",
    "    count += 1\n",
    "    action, _states = model.predict(state, deterministic=True)\n",
    "    next_state, reward, done, t, info = env.step(action)\n",
    "    #if reward < -10:\n",
    "        #print(state, action, reward)\n",
    "    if count > 500:\n",
    "        done = True\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    trajectory_x.append(env.xy_p[0])  # 更新无人机路径的x坐标\n",
    "    trajectory_y.append(env.xy_p[1])  # 更新无人机路径的y坐标\n",
    "    trajectory_ex.append(env.xy_e[0])  # 更新无人机路径的x坐标\n",
    "    trajectory_ey.append(env.xy_e[1])  # 更新无人机路径的y坐标\n",
    "\n",
    "# 绘制无人机路径\n",
    "ax.plot(trajectory_x, trajectory_y, color='red', linewidth=0.5)\n",
    "ax.plot(trajectory_ex, trajectory_ey, color='red', linewidth=0.5)\n",
    "\n",
    "# 打印每个episode的总奖励\n",
    "print('Total reward:', total_reward)\n",
    "\n",
    "# 显示子图窗口\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T07:37:35.804814300Z",
     "start_time": "2024-04-18T07:37:35.417777800Z"
    }
   },
   "id": "3c11d5f894713807"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d9d72f5dd5e50e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 逐渐学习ing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e984e89f12d31de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "\n",
    "# 加载预训练的模型\n",
    "model = PPO.load(\"best_model\")\n",
    "\n",
    "# Evaluation callback\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    eval_freq=500,\n",
    "    n_eval_episodes=4,\n",
    "    best_model_save_path=\".\",\n",
    "    log_path=\".\",\n",
    ")\n",
    "\n",
    "# 继续训练加载的模型\n",
    "model.learn(\n",
    "    total_timesteps=200000,\n",
    "    callback=eval_callback,\n",
    "    tb_log_name=\"ppo_run_\" + str(time.time()),\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1f70bd6af5331bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
